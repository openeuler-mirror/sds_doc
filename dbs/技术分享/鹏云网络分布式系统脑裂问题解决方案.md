随着业务的快速发展，业务的复杂性越来越高，目前大部分企业都在从集中式走向分布式。对于采用分布式系统的企业而言，系统出现数据丢失与损坏的情况是非常严重的，极易影响业务系统的正常稳定运行。其中，可能引起数据丢失的“**脑裂(split-brain)**”就是分布式系统中常会发生的问题。

# **“脑裂”问题**

**SPLIT BRAIN**

一套大规模的分布式系统往往由大量的组组成，组又由来自不同机器的成员组成，每个成员可以是不同机器上的不同设备，比如存储介质上某一段存储空间，这些机器通过网络连接，形成一个分布式集群。

分布式集群在网络正常的情况下，可以顺利地选举出集群Leader。但当集群内部的网络通信出现异常时，就有可能在不同的网络分区中选举出各自的Leader。这也就是“脑裂”问题。

通俗来讲，“脑裂”即“大脑分裂”，通常会出现在分布式集群环境中，比如 ElasticSearch集群与Zookeeper集群。这些集群环境有一个统一的特点——有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。

由于网络通信故障、节点负载过大等原因使得心跳检测超时，主备切换后分裂出了两个或多个主节点，由此导致决策之间发生冲突，从而引发分布式系统管理混乱、数据损坏的现象。

![](https://oscimg.oschina.net/oscnet/up-1e4a5b350a864bdc32796dc623f4ddcd75f.png)

图1

一定规模的分布式集群在运行一段时间后，可能会出现集群内部的网络异常，导致脑裂问题出现。当脑裂出现时会影响一个或多个组，受影响的组轻则无法正常进行IO操作，影响业务数据写入和读取，重则导致数据不一致，甚至数据损坏出现。同时，用户业务数据并发情况下，同一时间会通过多个数据驱动向同一组发送数据请求情况，以致出现管理混乱的现象。

如果发生脑裂后，客户端还没来得及切换到新的leader 2，连的还是leader 1，那么有些数据还是写入到了leader 1里面，leader 2没有这些数据。等leader 1恢复后会被作为备用连到集群环境，此时其自身数据会被清空，重新从leader 2复制数据。但leader 2由于之前并没有写入数据，实际上它是不存在数据的。也就是说leader 1清空了原有数据，leader 2没有写入数据，两者之间实际上是都没有数据的，所以才导致了原有数据的丢失。

因此，**正确处理多个数据驱动并发操作时的组中成员脑裂问题，是保障分布式系统正常运行的基础。**

# **“脑裂”问题解决方案**

**SOLUTIONS TO SPLIT BRAIN**

常规的脑裂问题解决方法是引入可信任的协调者（C oordinator）， 在鹏云网络已获得专利认可的 **自研的分布式存储系统及分布式存储系统的读写方法技术** 里，对“脑裂”问题有独特的解决方案：

## **01 正常网络情况**

数据驱动接收到用户读写数据后，将正常读写请求发送给组中所有成员，成员接收到数据请求后，对数据进行处理，接着把处理结果返回给数据驱动，数据驱动收集到成员数据处理结果后进行处理，最后返回读写数据响应给用户。

举例说明：数据驱动1简称为C1（Coordinator 1），数据驱动2简称为C2（Coordinator 2），主成员简称为P1（Primary 1），一般成员1简称为S1（Secondary 1），一般成员2简称为S2（Secondary 2）：

![](https://oscimg.oschina.net/oscnet/up-f7fc9787b26b7c4ac757cbabe22b3d884d4.png)

图2

如图2所示，C1和C2对一个正常的数据卷（假定该数据卷只有一个组）进行数据操作。数据写请求发送到C1后，会由C1同时发送数据写请求到P1、S1、S2三个组成员，随后由C1收集成员的写数据响应，出现以下3种情况:

1）P1、S1写数据响应成功;

2）P1、S2写数据响应成功；

3）P1、S1、S2写数据响应成功。

上述三种情况都可认为该数据写请求成功。

而读数据请求发送到C1后，会由C1发送读数据请求到P1，同时发送检测读数据请求(不会读取任何数据，但会携带当前组信息，仅仅一次握手验证)给S1、S2，同理，由C1收集P1、S1、S2 读数据响应，出现以下3种情况：

1）P1读数据响应成功，S1 检测读数据响应成功；

2）P1读数据响应成功，S2检测读数据响应成功；

3）P1读数据响应成功，S1、S2检测读数据响应成功。

以上三种情况都可认为该读数据请求成功。

## **02 异常网络情况**

环境出现异常时，比如存储介质、节点或网络故障等，会导致成员无法正常提供服务。假设此时出现下面脑裂情况：

![](https://oscimg.oschina.net/oscnet/up-6f552f41a459cf1a7906fdba7e927fe7010.png)

图3

假设网络发生故障，出现图3情况：P1和C1在一个网络分区A，new P1、S2和C2在另外一个网络分区B，网络分区A与网络分区B之间无法通信。

1) 写数据请求：

-   网络分区A：C1只能发送数据写请求到P1，只收到P1 数据写响应 OK，不符合之前列举的三种情况之一，写数据请求失败；
    
-   网络分区B：C2发送数据写请求到新的主成员P1(之前的S1)，一般成员S2，收到新的主成员P1、一般成员S2写数据响应成功，符合三种情况之一，写数据请求成功。
    

由此可见，网络分区A不可进行写操作，而网络分区B可以进行正常写操作，不会存在网络故障后网络分区A、网络分区B都可以进行写操作的脑裂现象。

2) 读数据请求：

-   网络分区A：C1只能发送读数据请求到P1，只收到P1读数据响应成功，不符合之前列举的三种情况之一，读数据请求失败；
    
-   网络分区B：C2发送读数据请求到新的主成员P1(之前的S1)，一般成员S2，收到新的主成员P1 读数据响应成功，一般成员S2 检测读数据响应成功，符合三种情况之一，读数据请求成功。
    

由此可见，网络分区A不可进行读操作，网络分区B可以进行读操作,不会存在网络故障后网络分区A、网络分区B都可以进行读操作的脑裂现象。这也是我们为什么设计对一般成员进行检测读请求的原因。

# **鹏云解决方案优势**

**ADVANTAGES OF SPLIT BRAIN SOLUTIONS**

相较于常规的脑裂问题解决方案，鹏云网络给出的解决方案是基于**纯自研的分布式存储技术**展开的，在此情况下存在以下两点主要优势：

1、多个数据驱动并发操作时，每个数据驱动的每个数据读请求都要获得组中大多数成员支持，可从根本上杜绝脑裂情况发生，防止数据不一致、损坏情况出现；

2、第一时间在组中找出可以继续进行数据操作的大多数成员，对其发送数据操作请求并快速响应用户，以保证用户业务准确性与连续性。其具有一定的普遍性，适用于所有分布式组；同时还具备可移植性和精确性优势。

-   可移植性：采用程式化算法，即可杜绝脑裂产生，与系统其他模块解耦合。
    
-   精确性：准备识别脑裂后可以一起正常接受业务请求的大部分成员，即不错判，也不会漏判。
    

**本文结束**